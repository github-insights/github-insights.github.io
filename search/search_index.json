{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Github Metrics","text":"<p>A highly configurable plug and play service to visualize all of your organizations Actions, Pull requests, Self hosted Runners ...</p> <p>Have you ever had to view manage a large Github organization with many repositoriess?  Github Metrics allows you to collect data from mulitple repositories into a single point  of truth giving you insights into, workflow run results, run times, total count metrics and much more.</p> <p></p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started pull the latest image from our package repository and after setting the minimal configuration deploy it on your infrastructure of choice. The application will expose all metrics on the <code>/actuator/prometheus</code> endpoint. A more detailed step by step guide can be found here</p>"},{"location":"#contributing","title":"Contributing","text":"<p>This project is open source so all contributions are welcome. If you are not sure of what could be added, we have a page dedicated to ideas and improvements to Github Metrics.</p>"},{"location":"#metrics","title":"Metrics","text":"<p>Looking for a list of all exposed data, check out the Metrics page.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>Through environment variables the service is highly configurable, many of the values can be configured to your liking. To find out what exactly can be configured go here to find a list of all environment variables.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Before diving into the details of the architecture here is a quick overview of the current architecture. This drawing omits some details of the actual  architecture but is still correct for the most part. </p> <p> </p>"},{"location":"architecture/#overview","title":"Overview","text":"<p>The project is based on a Hexagonal architecture, this allows for the the GitHub and Prometheus specific code to live in its own adapters and  exporters making the service easily extensible. Those two adapter and exporter implementations are built around a <code>domain</code> module.</p> <p>This also means that anything specific to the implementation of the adapter or the exporter is only present in each respective module and does not need to be considered from other modules. Examples would be that caching requests is done in the <code>github-adapter</code> and not in the <code>domain</code>. </p> <p> </p>"},{"location":"architecture/#domain","title":"Domain","text":"<p>The domain exposes different use cases for getting the data from the adapter implementation. This data, although modeled after the Github apis structure is not completly coupled to it and is already more generic then Github's. Fetching the data happens through implementations of the respective <code>...QueryPort</code> injected by spring.</p> <p>Since much of the data depends on eachother, like Workflow Runs are part of a Repository, the use cases call eachother to fetch the nessesary data.</p>"},{"location":"architecture/#prometheus-exporter","title":"Prometheus Exporter","text":"<p>Through the Micrometer dependency the prometheus exporter exposes its metrics on the <code>/actuator/prometheus</code> endpoint. Internally the exporter calls the domain's use cases transforming the returned data into a format that  is specific to each <code>Exporter</code> and then exposing it. </p> <p>Each exporter runs on a scheduled interval to fetch new data. This interval can be very frequent since the exporter should not be concerned about source details like ratelimiting. The interval is nontheless configurable, you can find the possible configurations here</p> <p> </p>"},{"location":"architecture/#github-adapter","title":"Github Adapter","text":"<p>As mentioned in the domain section of this page, the adapter implementation should implement all <code>QueryPort</code>'s with which the data gets fetched. Our implementation uses springs <code>RestClient</code> to do this making all the nessesary requests to fetch the data.</p> <p> </p>"},{"location":"architecture/#mapping-to-domain","title":"Mapping to Domain","text":"<p>This topic is explored more in the Api to Domain Mapping page but I thought I would mention a few things here. Each request response gets gets mapped to a <code>github-adapter</code> specific class which then knows how to turn itself into the relevant <code>domain</code> class. This allows the domain structure to be somewhat decoupled from Githubs internal structure and easy extension to other Github like Api's. For more details on this mapping go to the above mentioned page</p>"},{"location":"architecture/#request-caching","title":"Request Caching","text":"<p>To avoid slamming the Api with thousands of requests the adapter uses springs <code>@Cachable</code> annotation to cache function calls. This is especially important becuase a lot of use cases need the same data which would lead to a lot of unnessesary requests.</p>"},{"location":"architecture/#example","title":"Example","text":"<p>The list of repositories is needed by almost all use cases. The number of workflow runs or the number of self hosted runners is repository specific, for this reason all these use cases will make a call to the <code>RepositoriesQueryPort</code> and fetch the nessesary data. But after the first call this result actually almost never changes. Here a cached result comes in handy since it avoids the high number of actual requests to the Api.</p>"},{"location":"contributing/","title":"Ideas for Contributions","text":"<p>There is obviously the possiblity to add new Adapter and Exporter but aside from those bigger features there are a number of things that could be improved on the current codebase.</p> <ul> <li>Additional Metrics</li> <li> <p>Repository label</p> <p>Currently all metrics exposed by Github Metrics are in no way tied to the repository they come from. Although it adds a lot of cardinality it could be interesting to add the repository as a metric on every metric.</p> </li> <li> <p>Repository grouping</p> <p>Instead of putting the single repository label on every metric we could also add some other kind of grouping. An example would be the tags that repositories can have. Add those tags as labels on the metrics.</p> </li> <li> <p>Webhooks</p> <p>All data needs to be fetched periodically which causes a lot of unnessesray requests. To circumvent this you could make it possible ot listen for webhooks and only start requesting once Github tells you to. That said this is a bit more complex since it would expose endpoints on the open internet.</p> </li> <li> <p>improve Startup Sequence</p> <p>Currently the service struggles on startup since all the caches need to be filled. To improve this situation, add some kind of functionality to stagger the requests or something else to avoid the number of requests on startup.</p> </li> </ul>"},{"location":"contributing/#new-adapters-and-exporters","title":"New Adapters and Exporters","text":"<p>Seeing as Github Metrics is built in a hexagonal was it is quite easy to extend it and add more adapters and exporters as preferred. So here is a non exhaustive list of ideas for new adapter and exporters that could be added.</p>"},{"location":"contributing/#adapters","title":"Adapters","text":"<p>When it comes to adapters for other git hosting services there are a number of different adapters that could be built, that said there probably would be some changes needed on the <code>domain</code> side to be able to properly implement them. This would mean generizising the domain to better fit the generic git usecase rather then the specific Github one.</p> <ul> <li>Gitlab</li> <li>Bit Bucket</li> <li>Travis CI</li> <li>... and more</li> </ul>"},{"location":"contributing/#exporters","title":"Exporters","text":"<p>On the exporters side we have a lot more choices since the data returned by the use cases is quite generic and not rarrowed down to a very specific usecase yet, meaning that that work is on the part of the exporter. </p> <ul> <li>Relational Database</li> <li>Rest Api</li> <li>... and more</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>To get started pull the latest image from our package repository and after setting the minimal configuration  deploy it on your infrastructure of choice. The application will expose all  metrics on the <code>/actuator/prometheus</code> endpoint.</p>"},{"location":"getting-started/#authentication","title":"Authentication","text":"<p>To be able to make requests to the Github Api on your behalf Github Metrics uses Github Apps. The <code>AuthApp Github Metrics</code> has the correct privileges to only access the nessesary data. To use it simply install it on your organization and generate a private key which is then used to set the <code>APP_GITHUB_APPLICATION_PEM</code> env variable. </p> environment variables description APP_GITHUB_APPLICATION_ID The ID of the Github App installed for authorizing the Api calls made by Github Metics (In the case of `AuthApp Github Metrics` is: **882159**) APP_GITHUB_APPLICATION_INSTALL_ID                  The id of the installation of the above mentioned Github App.                  Can be retrived from the url when visiting <code>https://github.com/organizations/&lt;your-org&gt;/settings/installations</code>                 and then clicking on Configure for <code>AuthApp Github Metrics</code> APP_GITHUB_APPLICATION_PEM                  A private key generated through the installation of the Github                 App. This environement variable is just the whole <code>pem</code>                 string provided by Github. For more information on how to create                 this Github App check out the github authentication                 page.              <p>Github Metrics will only request the repositories that you give the app the access to. Any other repositories that are not added in the Apps list will be completly ignored.</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>After setting the minimal configuration the application should start running without problems. If you are interested in tuning the service to work better for specialized needs there are a number of environment variables that can be set to change the behaviour of the service. Before getting into the list please consider that some understanding of the inner workings of the service is required. You can find details on the architecture page.</p> <p>The two main things that can be configured are the exporting schedule as well as the cache eviction. For the exporting shedule you can find a list of the things to configure here. </p> <p>As for the Cache eviction the configuration is more important and not as simple. The cache eviction schedule can be configured, determining how often new data is fetched but then you can also determine at what status level the rate limiter will decide to completly stop fetching new data. For this set the <code>&lt;your-metric&gt;..STOP_EVICTION_STATUS</code> to one of the following:</p> <pre><code>\"CRITICAL\", \"WARNING\", \"CONCERNING\", \"GOOD\", \"OK\", \"\"\n</code></pre>"},{"location":"getting-started/#grafana","title":"Grafana","text":"<p>Grafana is a great tool for visualizing time series data so is a perfect solution to display the data generated by this service. If you are planning on also using Grafana to visualize your data we provide a few example json exports as well as some great example dashboards that you can copy from as  you wish a public dashboard to explore different ways of visualizing the data our serivce provides.</p>"},{"location":"getting-started/#deployment-example","title":"Deployment Example","text":"<p>For deploying Github Metrics we decided to use Grafana Cloud which had a few influences on the final deployment of the service. Normally prometheus is based on a pull model where prometheus pulls your data but when using Grafana Cloud you have to be the one to push to it, meaning a push model. Since we didn't want to change the service itself we decided to add Grafana Alloy as a sidecar to serve as both the one pulling from our service and pushing to Grafana Cloud.</p> <p>This in between actor did add some latency concerns since the scrape interval can, in the worst case add a whole scrape interval time to the latency. (In our case 10s)</p>"},{"location":"metrics/","title":"Metrics","text":"<p>All metrics also have a <code>organization</code> tag on them with the set organization as the value. Although not that important it is nice in the case that the service is being used on two organizations at the same time but pushing the data to a  single frontend.</p> metric name labels description Repositories <code>repositories_count</code> <code>organization</code>                  All Repositories that the Github Installation token has access                 to and exposes a total current count metric.              Workflow Runs <code>workflow_runs</code> <code>organization</code> <code>status</code> {DONE, IN_PROGRESS, PENDING, FAILED}                               For all Repositories retrieves all workflow runs from the start                 of yesterday until time of export and display a count of them                 for every status.              <code>active_workflow_runs</code> <code>organization</code> <code>status</code> {DONE, IN_PROGRESS, PENDING, FAILED}                               For all Repositories all active workflow runs and display a                  count of them for every status.              <code>workflow_runs_total_build_times</code> <code>organization</code>                  For all Repositories the total build time of the workflow runs                 from the start of yesterday until the time of export.              <code>workflow_runs_average_build_times</code> <code>organization</code>                  For all Repositories the average build time of the workflow runs                 from the start of yesterday until the time of export              Jobs <code>workflow_run_jobs</code> <code>organization</code> <code>status</code> {DONE, PENDING, IN_PROGRESS} <code>conclusion</code> {SUCCESS, FAILURE, ACTION_REQUIRED, NEUTRAL}                               For all Workflow runs of the last day retrieve all jobs and a                 count of every status/conclusion.              Pull Requests <code>pull_requests_count_of_last_{X}_days</code>                 {1,2,7,28,365}              <code>organization</code> <code>state</code> {OPEN, CLOSED, MERGED}                               For pull requests of the last days a count of each state              <code>pull_request_throughput_of_last_{X}_days</code>                 {7,14,28,365}              <code>organization</code>                  Merged Pull Requests per day over the period X              Self Hosted Runners <code>self_hosted_runners</code> <code>organization</code> <code>os</code> {MAC_OS, LINUX, WINDOWS} <code>status</code> {OFFLINE, IDLE, BUSY}                               For all selfhosted runners of the org/repos a count of their                 Operating System and Status."},{"location":"configuration/configuration/","title":"Configuration","text":""},{"location":"configuration/configuration/#authentication","title":"Authentication","text":"<p>FIXME: add things</p>"},{"location":"configuration/configuration/#exporters","title":"Exporters","text":"<p>These configs define on which schedule the exporters will run. Although configurable this is not so influential on the programs performance or latency and should be kept on quite a quick schedule. Most of the schedule executions will only hit the caches. To change how often the Github Api is queried use the enviroment variables listed in the cache eviction section.</p> datatype default description Workflow Runs <code>EXPORTERS_SCHEDULING_WORKFLOW_RUNS</code> java cron string <code>*/30 * * * * ?</code> export schedule for workflow runs Active Workflow Runs <code>EXPORTERS_SCHEDULING_ACTIVE_WORKFLOW_RUNS</code> java cron string <code>*/30 * * * * ?</code> export schedule for active workflow runs Jobs <code>EXPORTERS_SCHEDULING_JOBS</code> java cron string <code>*/30 * * * * ?</code> export schedule for workflow jobs Workflow Run Build Times <code>EXPORTERS_SCHEDULING_WORKFLOW_RUN_BUILD_TIMES</code> java cron string <code>45 */30 * * * ?</code> export schedule for workflow build times Pull Requests <code>EXPORTERS_SCHEDULING_PULL_REQUESTS</code> java cron string <code>30 */30 * * * ?</code> export schedule for pull requests Self Hosted Runners <code>EXPORTERS_SCHEDULING_SELF_HOSTED_RUNNERS</code> java cron string <code>*/30 * * * * ?</code> export schedule for self hosted runners Repository Count <code>EXPORTERS_SCHEDULING_REPOSITORY_COUNT</code> java cron string <code>*/30 * * * * ?</code> export schedule for repository count Rate Limit State <code>EXPORTERS_SCHEDULING_API_RATELIMIT_STATE</code> java cron string <code>*/15 * * * * ?</code> export schedule for the ratelimiters state"},{"location":"configuration/configuration/#cache-eviction","title":"Cache eviction","text":"<p>As mentioned above, this is the important part of the configuration. If you are intending to make the request interval significantly faster or slower change the cron shedule to the corresponding shedule leading to the cache beeing evicted more or less often and new data being fetched more or less frequently.</p> <p>That said the rate limiter might stop you from making too many requests by setting its status to a specific level. But even here you get to control how this level influences the features. Each feature can set a level at which it will be turned off. The logic works in the following way (as pseudocode):</p> <pre><code>shouldICacheEvict = if apiRateLimitStatus &lt; configuredValue { yes } else { no }\n</code></pre> <p>There is a possibility to also set no value (<code>\"\"</code>) which will lead to the feature always beeing active unless the actual ratelimit is hit in which case all action is ceased. The configured <code>enum string</code> can be one of:</p> <pre><code>\"CRITICAL\", \"WARNING\", \"CONCERNING\", \"GOOD\", \"OK\", \"\"\n</code></pre> datatype default description Workflow Runs <code>CACHE_EVICTION_SCHEDULING_WORKFLOW_RUNS</code> java cron string <code>30 */5 * * * ?</code> schedule on which to evict workflow runs <code>CACHE_EVICTION_WORKFLOW_RUNS_STOP_EVICTION_STATUS</code> enum string <code>CONCERNING</code> status on which to stop evicting workflow runs Active Workflow Runs <code>CACHE_EVICTION_SCHEDULING_ACTIVE_WORKFLOW_RUNS</code> java cron string <code>30 * * * * ?</code> schedule on which to evict active workflow runs <code>CACHE_EVICTION_ACTIVE_WORKFLOW_RUNS_STOP_EVICTION_STATUS</code> enum string status on which to stop evicting active workflow runs Jobs <code>CACHE_EVICTION_SCHEDULING_JOBS</code> java cron string <code>0 */5 * * * ?</code> schedule on which to evict jobs <code>CACHE_EVICTION_JOBS_STOP_EVICTION_STATUS</code> enum string <code>CONCERNING</code> status on which to stop evicting jobs Workflow Run Build Times <code>CACHE_EVICTION_SCHEDULING_WORKFLOW_RUN_BUILD_TIMES</code> java cron string <code>10 0 * * * ?</code> schedule on which to evict workflow build times <code>CACHE_EVICTION_WORKFLOW_RUN_BUILD_TIMES_STOP_EVICTION_STATUS</code> enum string <code>CONCERNING</code> status on which to stop evicting workflow build times Pull Requests <code>CACHE_EVICTION_SCHEDULING_PULL_REQUESTS</code> java cron string <code>15 0 * * * ?</code> schedule on which to evict pull requests <code>CACHE_EVICTION_PULL_REQUESTS_STOP_EVICTION_STATUS</code> enum string <code>GOOD</code> status on which to stop evicting pull requests Self Hosted Runners <code>CACHE_EVICTION_SCHEDULING_SELF_HOSTED_RUNNERS</code> java cron string <code>20 */5 * * * ?</code> schedule on which to evict self hosted runners <code>CACHE_EVICTION_SELF_HOSTED_RUNNERS_STOP_EVICTION_STATUS</code> enum string <code>CONCERNING</code> status on which to stop evicting self hosted runners Repository Count <code>CACHE_EVICTION_SCHEDULING_REPOSITORY_COUNT</code> java cron string <code>0 0 * * * ?</code> schedule on which to evict repository count <code>CACHE_EVICTION_REPOSITORY_COUNT_STOP_EVICTION_STATUS</code> enum string <code>GOOD</code> status on which to stop evicting repository count"},{"location":"configuration/configuration/#rate-limiter","title":"Rate Limiter","text":"<p>First we have some basic variables that allow for some minor configurations. If you are not intending to get really into optimizing the service there should be no need to touch these.</p> datatype default description State Control Schedule <code>APP_GITHUB_RATELIMITING_STATE_CONTROL_CHECK_SCHEDULE</code> java cron string <code>0 */5 * * * ?</code> how often the rate limiter will check if it can start making requests again if it happens to have gotten itself stuck  State Recalculation Timing <code>APP_GITHUB_RATELIMITING_SECONDS_BETWEEN_STATE_RECALCULATIONS</code> integer (seconds) <code>60</code> Time that passes between each re-evaluation of how many requests are being made, shorter time will make the rate limiter more sensitive to bursts and longer the inverse Ratelimit Buffer <code>APP_GHITHUB_RATELIMIT_BUFFER</code> float <code>0.9</code> Percentage of the total limit that will be used. Allows for a bit of a buffer in case other applications are also using the same rate limit."},{"location":"configuration/configuration/#status-limits","title":"Status Limits","text":"<p>If you want to change at which point the rate limiter changes to which status  change these values. The rate limiter waits a number of seconds specified by <code>APP_GITHUB_RATELIMITING_SECONDS_BETWEEN_STATE_RECALCULATIONS</code> after which it calculates how many requests per second (req/s) have been made in that time. This number is then compared to a ideal req/s, calculate through rate limiting headers which then in turn determines the status.</p> <pre><code>if (ideal * GOOD_LIMIT &gt;= actual) {\n    \"OK\"\n} else if ...\n...\n} else {\n    \"CRITICAL\"\n}\n</code></pre> datatype default description GOOD <code>APP_GITHUB_RATELIMITING_GOOD_LIMIT</code> float <code>0.5</code> Percentage of the ideal req/s that need to be used for the status to minimally turn to \"GOOD\" CONCERNING <code>APP_GITHUB_RATELIMITING_CONCERNING_LIMIT</code> float <code>0.7</code> Percentage of the ideal req/s that need to be used for the status to minimally turn to \"CONCERNING\" WARNING <code>APP_GITHUB_RATELIMITING_WARNING_LIMIT</code> float <code>0.9</code> Percentage of the ideal req/s that need to be used for the status to minimally turn to \"WARNING\" CRITICAL <code>APP_GITHUB_RATELIMITING_CRITICAL_LIMIT</code> float <code>1.2</code> Percentage of the ideal req/s that need to be used for the status to minimally turn to \"CONCERNING\""},{"location":"configuration/configuration/#feature-toggles","title":"Feature Toggles","text":"<p>With these toggles you can decide what metrics will be exported by Github Metrics. Although turning off features will reduce the number of requests made the relationship is not linear. The feature toggles will not directly stop certain endpoints from being requested they will just stop the exporter from asking for that data. As an example, Repositories will always be requested if any other feature is active since for exaples to fetch WorkflowRuns we need to know what repositories are  available.</p> datatype default description Workflow Runs <code>EXPORTER_WORKFLOW_RUNS_FEATURE</code> boolean <code>true</code> Collects data on all workflow runs of the last 24 hours, this includes workflow-runs of all statuses. Active Workflow Runs <code>EXPORTER_ACTIVE_WORKFLOW_RUNS_FEATURE</code> boolean <code>false</code> Collects data only the the currently active workflow-runs, meaning any workflow-run that has not failed or completed. Jobs <code>EXPORTER_JOBS_FEATURE</code> boolean <code>false</code> Collects data on all jobs of all the workflow-runs started in the last 24 hours. Repository Count <code>EXPORTER_REPOSITORIES_FEATURE</code> boolean <code>true</code> Collects data on the number of repositories in the organization. Workflow Run Build Times <code>EXPORTER_WORKFLOW_RUN_BUILD_TIMES_FEATURE</code> boolean <code>false</code> Aggregates workflow-run build-times to both a total count as well as a average for all workflow-runs created since yesterday 00:00. Self Hosted Runners <code>EXPORTER_SELF_HOSTED_RUNNERS_FEATURE</code> boolean <code>false</code> Collects data on all self-hosted runners present on the organization as well as any repository that the token has access to. Pull Requests <code>EXPORTER_PULL_REQUESTS_FEATURE</code> boolean <code>false</code> Aggregates status counts of pull requests over the last few days."},{"location":"configuration/minimal-config/","title":"Minimal Config","text":"<p>To get started with the service there is a minimal amount of configuration needed to get the service running. This configuration contains the following:</p> environment variables datatype description APP_GITHUB_ORG string the name of the organization APP_GITHUB_APPLICATION_ID number                  The id of the Github App installed for authorizing the Api calls                 made by Github Metics (In the case of `AuthApp Github Metrics` is:                 882159)              APP_GITHUB_APPLICATION_INSTALL_ID number                  The id of the installation of the above mentioned Github App.                  Can be retrived from the url when visiting <code>https://github.com/organizations/&lt;your-org&gt;/settings/installations</code>                 and then clicking on Configure for <code>AuthApp Github Metrics</code> APP_GITHUB_APPLICATION_PEM string with newlines                  A private key generated through the installation of the Github                 App. This environement variable is just the whole <code>pem</code>                 string provided by Github. For more information on how to create                 this Github App check out the github authentication                 page.              <p>By default only the <code>Repository Count</code> and <code>Workflow Runs</code> features are active. If you would like to collect any other metrics turn on the relevant features.</p> datatype default description Workflow Runs <code>EXPORTER_WORKFLOW_RUNS_FEATURE</code> boolean <code>true</code> Collects data on all workflow runs created since yesterday 00:00, this includes workflow-runs of all statuses. Active Workflow Runs <code>EXPORTER_ACTIVE_WORKFLOW_RUNS_FEATURE</code> boolean <code>false</code> Collects data only the the currently active workflow-runs, meaning any workflow-run that has not failed or completed. Jobs <code>EXPORTER_JOBS_FEATURE</code> boolean <code>false</code> Collects data on all jobs of all the workflow-runs created in the last 24 hours. Repository Count <code>EXPORTER_REPOSITORIES_FEATURE</code> boolean <code>true</code> Collects data on the number of repositories in the organization. Workflow Run Build Times <code>EXPORTER_WORKFLOW_RUN_BUILD_TIMES_FEATURE</code> boolean <code>false</code> Aggregates workflow-run build-times to both a total count as well as a average for all workflow-runs created in the last 24 hours. Self Hosted Runners <code>EXPORTER_SELF_HOSTED_RUNNERS_FEATURE</code> boolean <code>false</code> Collects data on all self-hosted runners present on the organization as well as any repository that the token has access to. Pull Requests <code>EXPORTER_PULL_REQUESTS_FEATURE</code> boolean <code>false</code> Aggregates status counts of pull requests over the last few days."},{"location":"github/api-to-domain-mapping/","title":"Api to Domain Mapping","text":""},{"location":"github/api-to-domain-mapping/#overview","title":"Overview","text":"<p>Since there are a lot of transformations happening from the github api to our internal <code>domain</code> model, here is a quick overview of it. The intermediary layer in the <code>github-adapter</code> serves to map the response json directly to java classes which then know how to transform themselves into actual <code>domain</code> classes. Aside from the whole classes, we are also mapping things like possible statuses. We do this because it reduces the cardinality of the resulting prometheus metric. Look below for more details.</p>"},{"location":"github/api-to-domain-mapping/#workflow-run","title":"Workflow Run","text":"<p>Both the conclusion as well as the status are grouped into the <code>WorkflowRunStatus</code> enum. This leads to some dataloss which is acceptable for the better decoupleing. First the <code>conclusion</code> is queried for what the final status should be but if it does not give a clear response then the <code>status</code> determines the final <code>WorkflowRunStatus</code>.</p>"},{"location":"github/api-to-domain-mapping/#conclusion","title":"Conclusion","text":"github status strings WorkflowRunStatus enum \"failure\" \"cancelled\" \"startup_failure\" FAILED \"success\" DONE \"neutral\" \"in_progress\" null passed on to status"},{"location":"github/api-to-domain-mapping/#status","title":"Status","text":"github status strings WorkflowRunStatus enum \"completed\" \"success\" DONE \"action_required\" \"cancelled\" \"failure\" \"neutral\" \"skipped\" \"stale\" \"timed_out\" FAILED \"in_progress\" IN_PROGRESS \"queued\" \"requested\" \"waiting\" \"pending\" PENDING"},{"location":"github/api-to-domain-mapping/#build-times","title":"Build Times","text":"<p>Although a separate query, there is no separate object on the domain. Insead the adapter sets the build time parameter on the domain after having done the query to the timing endpoint.</p> <p> </p>"},{"location":"github/api-to-domain-mapping/#jobs","title":"Jobs","text":"<p>Unlike Workflow Runs, Jobs has the <code>conclusion</code> and <code>status</code> split up into two  different enums. This should be changed in the future into one status to reduce complexity and coupling.</p>"},{"location":"github/api-to-domain-mapping/#conclusion_1","title":"Conclusion","text":"github conclusion strings JobConclusion enum \"success\" SUCCESS \"neutral\" \"skipped\" \"null\" NEUTRAL \"action_required\" ACTION_REQUIRED \"failure\" \"cancelled\" \"timed_out\" \"action_required\" FAILURE"},{"location":"github/api-to-domain-mapping/#status_1","title":"Status","text":"github status strings JobStatus enum \"requested\" \"queued\" \"pending\" PENDING \"in_progress\" IN_PROGRESS \"completed\" DONE"},{"location":"github/api-to-domain-mapping/#pull-request","title":"Pull Request","text":"<p>The Pull Requests endpoint is currently the only endpoint that returns an array on the root level which makes it a little different from the other response objects.</p> <p> </p>"},{"location":"github/api-to-domain-mapping/#repository","title":"Repository","text":""},{"location":"github/api-to-domain-mapping/#self-hosted-runner","title":"Self Hosted Runner","text":"<p>As displayed by the grafic below, self hosted runners can be present on both the organization as well as each repository. The response json is still the same in both cases simplifying the mapping quite a lot.</p> <p> </p>"},{"location":"github/authentication/","title":"Authentication","text":"<p>Authorization is done via a Github App which can be installed on a organization. We have created our own Github App specifically for this purpuse and you will have to do so too. To be able to perform all the nessesary actions the Github App needs to have the following priviliges.</p>"},{"location":"github/authentication/#setting-up-the-github-app","title":"Setting up the Github App","text":""},{"location":"github/authentication/#permissions","title":"Permissions","text":"permissions level read only permissions to be set Repository permissions Actions Administration Metadata Pull requests Organization permissions Administrartion Projects Self-hosted runners Account permissions none"},{"location":"github/authentication/#access-to-repositories","title":"Access to Repositories","text":"<p>This app then authorizes access to repositories on the organization. The exact repositories that it will have access to can be defined on installation as well as changed anytime under <code>&lt;your-org&gt;</code> &gt; <code>Settings</code> &gt; <code>Github Apps</code> &gt; <code>&lt;configure your-app&gt;</code></p>"},{"location":"github/authentication/#private-key-pem","title":"Private Key (<code>PEM</code>)","text":"<p>To actually authenticate the Service you will need to create a private key from the settings page of the App you can find the settings page here: <code>https://github.com/organizations/&lt;your-org&gt;/settings/apps/&lt;your-app-name&gt;</code>.</p> <p>Github supplies an RSA private key which needs to be used to sign a JWT with the details</p> <pre><code>{\n  \"iss\": \"&lt;install_id&gt;\",\n  \"exp\": 1714639080,\n  \"iat\": 1714638420\n}\n</code></pre> <p>iss -&gt; the installation id of the application</p> <p>exp -&gt; The expiration time of the JWT, after which it can't be used to request an installation token. The time must be no more than 10 minutes into the future.</p> <p>iat -&gt; The time that the JWT was created. To protect against clock drift, we recommend that you set this 60 seconds in the past and ensure that your server's date and time is set accurately (for example, by using the Network Time Protocol). </p> <p>this request then returns an app installation token which we can use to authenticate all future requests.</p> <p>Click here for full documentation of this process</p> <p>When adding the GH App to your organization you can select which repositories it has access to or simply all repositories in the organization. The service does a request to see which repositories it has access to and then only the metrics relative to those repositories are exported.</p> <p></p>"},{"location":"github/authentication/#rate-limiting","title":"Rate Limiting","text":""}]}